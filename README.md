# ğŸ”¬ AI Research Assistant

> An agentic RAG pipeline that takes any research question, searches the web, reads and filters the pages, and synthesizes a structured, cited report â€” all in under 45 seconds.

![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python)
![Streamlit](https://img.shields.io/badge/Streamlit-1.40-red?logo=streamlit)
![LangChain](https://img.shields.io/badge/LangChain-0.3.7-green)
![License](https://img.shields.io/badge/License-MIT-yellow)

---

## ğŸŒ Live Demo

**â†’ [your-app-name.streamlit.app](https://your-app-name.streamlit.app)**
*(replace with your actual Streamlit Cloud link after deployment)*

---

## What it does

1. **You type a question** â€” e.g. *"How does CRISPR gene editing work?"*
2. **The Agent (Llama 3.3 70B)** plans 3 optimized search queries targeting different angles
3. **Search API** fetches the top 5 results per query (15 results total, deduplicated)
4. **Scraper** fetches each page, strips nav/ads/boilerplate, extracts clean paragraph text
5. **Chunker** splits cleaned text into 500-char overlapping segments
6. **RAG (ChromaDB + MiniLM)** embeds all chunks locally and retrieves the 12 most relevant ones
7. **LLM (Llama 3.3 70B)** synthesizes a structured report with inline citations
8. **You get** a 4-section Markdown report (Intro, Key Findings, Contradictions, Conclusion + Sources)

---

## System Architecture

```
User Query
    â”‚
    â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ¤– AGENT (agent.py)        â”‚
â”‚  Llama 3.3 70B via Groq     â”‚
â”‚  Generates 3 search queries â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ 3 queries
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ” SEARCH (search.py)      â”‚
â”‚  SerpAPI or Brave Search    â”‚
â”‚  5 results Ã— 3 queries      â”‚
â”‚  Deduplicates by URL        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ ~10-15 URLs
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“„ SCRAPER (scraper.py)    â”‚
â”‚  requests + BeautifulSoup   â”‚
â”‚  Strips nav/ads/scripts     â”‚
â”‚  Extracts <p> text only     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ Cleaned text per page
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  âœ‚ï¸ CHUNKER (chunker.py)    â”‚
â”‚  RecursiveCharacterSplitter â”‚
â”‚  500 chars, 50 overlap      â”‚
â”‚  Tags each chunk with URL   â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ ~100-200 chunks
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ§  VECTOR STORE            â”‚
â”‚  (vector_store.py)          â”‚
â”‚  all-MiniLM-L6-v2 embeddingsâ”‚
â”‚  ChromaDB cosine search     â”‚
â”‚  Retrieves top 12 chunks    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚ 12 most relevant chunks
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  ğŸ“ SYNTHESIZER             â”‚
â”‚  (synthesizer.py)           â”‚
â”‚  Llama 3.3 70B via Groq     â”‚
â”‚  Structured report + cites  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
         ğŸ“‹ REPORT
```

---

## Tech Stack

| Component | Technology | Why |
|-----------|-----------|-----|
| LLM | Llama 3.3 70B via **Groq** | Free, fast (~500 tok/s), no cost |
| Agent framework | **LangChain** | ChatGroq integration, prompt management |
| Search | **SerpAPI** or **Brave Search** | Free tiers available |
| Scraping | **requests + BeautifulSoup** | Reliable HTML parsing |
| Text splitting | **LangChain TextSplitter** | Smart sentence-aware chunking |
| Embeddings | **all-MiniLM-L6-v2** | 100% local, 22MB, no API cost |
| Vector DB | **ChromaDB** | Local in-memory, no setup |
| UI | **Streamlit** | Fast Python web UI |

---

## Local Setup

### Prerequisites
- Python 3.11+
- Git

### 1. Clone the repo

```bash
git clone https://github.com/yourusername/research-assistant.git
cd research-assistant
```

### 2. Create virtual environment

```bash
python -m venv venv

# macOS/Linux
source venv/bin/activate

# Windows
venv\Scripts\activate
```

### 3. Install dependencies

```bash
pip install -r requirements.txt
```

> âš ï¸ First install downloads the MiniLM model (~22MB). This only happens once.

### 4. Set up API keys

```bash
cp .env.example .env
```

Edit `.env` and fill in your keys:

```env
GROQ_API_KEY=your_groq_key     # https://console.groq.com (free)
SERPAPI_KEY=your_serpapi_key   # https://serpapi.com (100/month free)
# OR
BRAVE_API_KEY=your_brave_key   # https://brave.com/search/api (2000/month free)
```

### 5. Run the app

```bash
streamlit run app.py
```

The app opens at `http://localhost:8501`

---

## Deployment (Streamlit Community Cloud)

1. Push your repo to GitHub (make sure `.env` is in `.gitignore`)
2. Go to [share.streamlit.io](https://share.streamlit.io)
3. Click **New app** â†’ select your repo â†’ set `app.py` as main file
4. Go to **Settings â†’ Secrets** and paste:

```toml
GROQ_API_KEY = "your_groq_key"
SERPAPI_KEY = "your_serpapi_key"
```

5. Click **Deploy** â€” you get a live public URL

---

## File Structure

```
research-assistant/
â”œâ”€â”€ app.py                  # Streamlit UI + pipeline orchestration
â”œâ”€â”€ requirements.txt        # All Python dependencies
â”œâ”€â”€ .env.example            # API key template (copy â†’ .env)
â”œâ”€â”€ .gitignore              # Excludes .env, __pycache__, etc.
â”œâ”€â”€ README.md               # This file
â”‚
â”œâ”€â”€ src/                    # All pipeline modules
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ agent.py            # LLM query planner (agentic layer)
â”‚   â”œâ”€â”€ search.py           # SerpAPI / Brave Search integration
â”‚   â”œâ”€â”€ scraper.py          # HTML fetcher + cleaner
â”‚   â”œâ”€â”€ chunker.py          # Text splitter
â”‚   â”œâ”€â”€ vector_store.py     # ChromaDB + MiniLM RAG
â”‚   â””â”€â”€ synthesizer.py      # Report generator
â”‚
â””â”€â”€ .streamlit/
    â””â”€â”€ secrets.toml        # (gitignored) Streamlit Cloud secrets
```

---

## APIs Used

| API | Purpose | Free Tier | Link |
|-----|---------|-----------|------|
| **Groq** | LLM inference (Llama 3.3 70B) | Generous free tier | [console.groq.com](https://console.groq.com) |
| **SerpAPI** | Google Search results | 100 searches/month | [serpapi.com](https://serpapi.com) |
| **Brave Search** | Web search (alternative) | 2000 queries/month | [brave.com/search/api](https://brave.com/search/api/) |

**Zero-cost local components**: MiniLM embeddings, ChromaDB â€” run entirely on your machine.

---

## Example Output

**Query:** *"What are the latest breakthroughs in fusion energy?"*

```markdown
## Introduction
Nuclear fusion has long been considered the holy grail of clean energy...

## Key Findings
The National Ignition Facility achieved ignition in December 2022 [1], marking...
Private companies like Commonwealth Fusion Systems have raised over $1.8B [2]...

## Contradictions & Open Debates
While NIF's achievement was historic, critics note it required 300x more energy [3]
to power the facility than the 3.15 MJ delivered to the target...

## Conclusion
Fusion energy is transitioning from theoretical to engineering challenges...

## Sources
[1] NIF Ignition Achievement â€” https://...
[2] CFS Funding Round â€” https://...
```

---

## License

MIT â€” free to use, modify, and deploy.
